{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tensorflow.keras.preprocessing.\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from collections import namedtuple\n",
    "import lmdb\n",
    "from dataloader_iam import *\n",
    "from preprocessor import *\n",
    "from model import *\n",
    "from main import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_path = \"/Users/nicolacave/dsi_galvanize/capstones/capstone3/handwriting_reader/data/img\"\n",
    "word_folders = [i for i in os.listdir(base_path) if not i == '.DS_Store']\n",
    "# word_folders.remove('.DS_Store')\n",
    "print(f\"num folders: {len(word_folders)}\")\n",
    "img_paths = []\n",
    "\n",
    "# print(f\"base_path: {base_path}\")\n",
    "\n",
    "# Populate list of image filepaths\n",
    "\n",
    "for folder in word_folders:  \n",
    "    path = os.path.join(base_path,folder)\n",
    "    word_subfolders = [i for i in os.listdir(path) if not i == '.DS_Store']\n",
    "    # print(f\"folder: {folder}\")\n",
    "    # print(f\"path: {path}\") \n",
    "    for subfolder in word_subfolders:\n",
    "        newpath = os.path.join(path, subfolder)\n",
    "        # print(f\"subfolder: {subfolder}\")\n",
    "        # print(f\"newpath: {newpath}\")\n",
    "        for img in os.listdir(newpath):\n",
    "            # print(f\"img: {img}\")\n",
    "            # print(path+\"/\"+folder+\"/\"+img)\n",
    "            img_path = newpath + \"/\" + img\n",
    "            img_paths.append(img_path)\n",
    "            \n",
    "print(f\"num images: {len(img_paths)}\")\n",
    "# print(img_paths[444])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_arr = np.array(img_paths)\n",
    "img_arr.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get corresponding text labels\n",
    "\n",
    "data_dir = \"/Users/nicolacave/dsi_galvanize/capstones/capstone3/handwriting_reader/data\"\n",
    "f = open(data_dir + \"/\" + 'gt/words.txt')\n",
    "chars = set()\n",
    "bad_samples_reference = ['a01-117-05-02', 'r06-022-03-05']  # known broken images in IAM dataset\n",
    "file_names = []\n",
    "img_labels = []\n",
    "for line in f:\n",
    "    # ignore comment line\n",
    "    if not line or line[0] == '#':\n",
    "        continue\n",
    "\n",
    "    line_split = line.strip().split(' ')\n",
    "    assert len(line_split) >= 9\n",
    "    img_labels.append(line_split[8])\n",
    "    # filename: part1-part2-part3 --> part1/part1-part2/part1-part2-part3.png\n",
    "    file_name_split = line_split[0].split('-')\n",
    "    file_name_subdir1 = file_name_split[0]\n",
    "    file_name_subdir2 = f'{file_name_split[0]}-{file_name_split[1]}'\n",
    "    file_base_name = line_split[0] + '.png'\n",
    "    file_name = data_dir + \"/\" + 'img' + \"/\" + file_name_subdir1 + \"/\" + file_name_subdir2 + \"/\" + file_base_name\n",
    "    file_names.append(file_name)\n",
    "    #print(file_name)\n",
    "    if line_split[0] in bad_samples_reference:\n",
    "        print('Ignoring known broken image:', file_name)\n",
    "        continue\n",
    "\n",
    "    # GT text are columns starting at 9\n",
    "    gt_text = ' '.join(line_split[8:])\n",
    "    chars = chars.union(set(list(gt_text)))\n",
    "    \n",
    "    # put sample into list\n",
    "    samples = []\n",
    "    samples.append(Sample(gt_text, file_name))\n",
    "print(len(samples))\n",
    "print(len(file_names))\n",
    "print(len(img_labels))\n",
    "# print(chars)\n",
    "# print(img_labels[444])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create table of X and y\n",
    "\n",
    "file_names = pd.Series(file_names)\n",
    "print(len(file_names))\n",
    "img_labels = pd.Series(img_labels)\n",
    "df = pd.DataFrame(list(zip(file_names, img_labels)), columns=[\"file_name\", \"img_label\"])\n",
    "\n",
    "# read and resize images\n",
    "\n",
    "images = []\n",
    "for i in file_names:\n",
    "    curImg = cv2.imread(i)\n",
    "    print(curImg)\n",
    "    try:\n",
    "        curImg = cv2.resize(curImg, (1400, 1000), interpolation=cv2.INTER_AREA)\n",
    "        print(curImg.shape)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "height, width , layers = img.shape\n",
    "size=(width,height)\n",
    "print(size)\n",
    "curImg = cv2.resize(curImg, (32,32))\n",
    "images.append(curImg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create training set at 80%\n",
    "# Create testing set at 20%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(df[\"file_name\"]), np.array(df[\"img_label\"]), test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(train_words)\n",
    "# print(train_samples)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DATADIR = \"/Users/nicolacave/dsi_galvanize/capstones/capstone3/handwriting_reader/data/img\"\n",
    "\n",
    "# CATEGORIES = [i for i in os.listdir(DATADIR) if not i == \".DS_Store\"]\n",
    "# print(CATEGORIES)\n",
    "\n",
    "for category in CATEGORIES:  # do dogs and cats\n",
    "    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "    #print(path)\n",
    "    #if os.path.isdir(path):\n",
    "    for folder in os.listdir(path):\n",
    "        #print(f\"folder: {folder}\")\n",
    "        for img in os.listdir(path+\"/\"+folder):\n",
    "            #print(f\"img: {img}\")\n",
    "            #print(path+\"/\"+folder+\"/\"+img)\n",
    "            #if not img.startswith('.'):\n",
    "            img_array = cv2.imread(os.path.join(path,folder,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                #print(img_array)\n",
    "            #plt.imshow(img_array, cmap='gray')  # graph it\n",
    "            #plt.show()  # display!\n",
    "\n",
    "        #break  # we just want one for now so break\n",
    "    #break  #...and one more!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training_data = []\n",
    "#print(len(CATEGORIES))\n",
    "def create_training_data():\n",
    "    print(len(CATEGORIES)*0.8)\n",
    "    for category in CATEGORIES[:int(len(CATEGORIES)*0.8)]:  # do dogs and cats\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "        for folder in os.listdir(path):\n",
    "            for img in os.listdir(path+\"/\"+folder):\n",
    "        #for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "                try:\n",
    "                    img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                    new_array = cv2.resize(img_array, (128, 128), interpolation=cv2.INTER_AREA)  # resize to normalize data size\n",
    "                    training_data.append([new_array, class_num])  # add this to our training_data\n",
    "                except Exception as e:  # in the interest in keeping the output clean...\n",
    "                    print(e)\n",
    "                    #pass\n",
    "                #except OSError as e:\n",
    "                #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "                #except Exception as e:\n",
    "                #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "\n",
    "print(len(training_data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(training_data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",input_shape=[137,236,1]),#input shape: [rows, columns, channels]\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(training_data)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "24bd0a8d74f35437157cf36f14598ef3477f99df4cd340566b47027f8059ba3f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}